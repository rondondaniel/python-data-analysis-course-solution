{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des Données - Performance des Étudiants\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "Après avoir complété ce notebook, vous serez capable de :\n",
    "\n",
    "- Gérer les valeurs manquantes dans les ensembles de données\n",
    "- Corriger les formats de données\n",
    "- Standardiser et normaliser les données\n",
    "- Créer des groupes à partir de variables continues\n",
    "- Générer des variables indicatrices à partir de données catégorielles en utilisant l'encodage one-hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table des Matières\n",
    "\n",
    "1. [Importation des Données et Bibliothèques](#import-data)\n",
    "2. [Exploration des Données](#data-exploration)\n",
    "3. [Gestion des Valeurs Manquantes](#missing-values)\n",
    "4. [Correction des Formats de Données](#data-formats)\n",
    "5. [Standardisation des Données](#standardization)\n",
    "6. [Normalisation des Données](#normalization)\n",
    "7. [Discrétisation des Données](#binning)\n",
    "8. [Encodage One-Hot (Variables Indicatrices/Variables Dummy)](#indicator-variables)\n",
    "9. [Exportation des Données Nettoyées](#export-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"import-data\"></a>\n",
    "## 1. Importation des Données et Bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration du style de visualisation\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture du jeu de données\n",
    "file_path = \"StudentsPerformance.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Affichage des premières lignes du jeu de données\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-exploration\"></a>\n",
    "## 2. Exploration des Données\n",
    "\n",
    "Avant de commencer le nettoyage et la préparation de nos données, comprenons d'abord ce avec quoi nous travaillons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir des informations de base sur le jeu de données\n",
    "print(\"Dimensions du jeu de données:\", df.shape)\n",
    "print(\"\\nInformations sur le jeu de données:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir un résumé statistique du jeu de données\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier les doublons\n",
    "print(f\"Nombre de lignes dupliquées: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorons les variables catégorielles dans notre jeu de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier les valeurs uniques dans chaque colonne catégorielle\n",
    "categorical_columns = ['gender', 'race/ethnicity', 'parents_education', 'lunch', 'test_prep_course']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    print(f\"\\nValeurs uniques dans {column}:\")\n",
    "    print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"missing-values\"></a>\n",
    "## 3. Gestion des Valeurs Manquantes\n",
    "\n",
    "Vérifions s'il y a des valeurs manquantes dans notre jeu de données et traitons-les de manière appropriée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier les valeurs manquantes\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Valeurs manquantes dans chaque colonne:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nous trouvons des valeurs manquantes, nous pouvons les traiter en utilisant différentes méthodes :\n",
    "\n",
    "1. **Supprimer les lignes avec des valeurs manquantes**\n",
    "2. **Remplacer les valeurs manquantes par la moyenne, la médiane ou le mode**\n",
    "3. **Remplacer les valeurs manquantes selon une stratégie spécifique**\n",
    "\n",
    "Mettons en œuvre ces stratégies selon les besoins :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple: S'il y avait des valeurs manquantes dans les colonnes numériques, nous pourrions les remplacer par la moyenne\n",
    "numerical_columns = ['math_score', 'reading_score', 'writing_score']\n",
    "\n",
    "for column in numerical_columns:\n",
    "    if df[column].isnull().sum() > 0:\n",
    "        mean_value = df[column].mean()\n",
    "        df[column].fillna(mean_value, inplace=True)\n",
    "        print(f\"Valeurs manquantes remplacées dans {column} par la moyenne: {mean_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple: S'il y avait des valeurs manquantes dans les colonnes catégorielles, nous pourrions les remplacer par le mode\n",
    "for column in categorical_columns:\n",
    "    if df[column].isnull().sum() > 0:\n",
    "        mode_value = df[column].mode()[0]\n",
    "        df[column].fillna(mode_value, inplace=True)\n",
    "        print(f\"Valeurs manquantes remplacées dans {column} par le mode: {mode_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-formats\"></a>\n",
    "## 4. Correction des Formats de Données\n",
    "\n",
    "Vérifions les types de données de nos colonnes et assurons-nous qu'ils sont au format correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier les types de données\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les types de données si nécessaire\n",
    "# Par exemple, s'assurer que les colonnes numériques sont du type correct\n",
    "for column in numerical_columns:\n",
    "    df[column] = df[column].astype('float')\n",
    "\n",
    "# Vérifier à nouveau les types de données\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"standardization\"></a>\n",
    "## 5. Standardisation des Données\n",
    "\n",
    "La standardisation des données est le processus de transformation des données en un format commun qui permet une comparaison significative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créons une nouvelle fonctionnalité : score moyen\n",
    "df['average_score'] = (df['math_score'] + df['reading_score'] + df['writing_score']) / 3\n",
    "df['average_score'] = df['average_score'].round(2)\n",
    "\n",
    "# Afficher les premières lignes avec la nouvelle colonne\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une colonne réussite/échec basée sur le score moyen (exemple de standardisation)\n",
    "# En supposant que 60 est le score de passage\n",
    "df['pass_status'] = np.where(df['average_score'] >= 60, 'Réussite', 'Échec')\n",
    "\n",
    "# Afficher les premières lignes avec la nouvelle colonne\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"normalization\"></a>\n",
    "## 6. Normalisation des Données\n",
    "\n",
    "La normalisation est le processus de transformation des valeurs de plusieurs variables dans une plage similaire. Les techniques courantes de normalisation comprennent :\n",
    "\n",
    "1. **Mise à l'échelle Min-Max** : Met les valeurs à l'échelle dans une plage fixe de 0 à 1\n",
    "2. **Normalisation Z-score** : Standardise les valeurs en fonction de la moyenne et de l'écart-type\n",
    "\n",
    "Appliquons ces techniques à nos données numériques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise à l'échelle Min-Max\n",
    "for column in numerical_columns:\n",
    "    column_min = df[column].min()\n",
    "    column_max = df[column].max()\n",
    "    df[f'{column}_normalized'] = (df[column] - column_min) / (column_max - column_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation Z-score\n",
    "for column in numerical_columns:\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    df[f'{column}_standardized'] = (df[column] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisons la distribution des scores originaux et normalisés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des données originales vs normalisées pour le score en mathématiques\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(df['math_score'], kde=True)\n",
    "plt.title('Scores Mathématiques Originaux')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.histplot(df['math_score_normalized'], kde=True)\n",
    "plt.title('Scores Mathématiques Normalisés Min-Max')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.histplot(df['math_score_standardized'], kde=True)\n",
    "plt.title('Scores Mathématiques Standardisés Z-Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"binning\"></a>\n",
    "## 7. Discrétisation\n",
    "\n",
    "La discrétisation est un processus de transformation des variables numériques continues en 'bins' catégoriels discrets pour une analyse groupée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regroupement des scores mathématiques en catégories\n",
    "bins = [0, 40, 60, 80, 100]\n",
    "labels = ['Faible', 'Moyen', 'Bon', 'Excellent']\n",
    "df['math_score_category'] = pd.cut(df['math_score'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Afficher les premières lignes avec la colonne regroupée\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter le nombre d'étudiants dans chaque groupe\n",
    "math_category_counts = df['math_score_category'].value_counts().sort_index()\n",
    "print(math_category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les données regroupées\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='math_score_category', data=df, palette='viridis')\n",
    "plt.title('Distribution des Catégories de Scores en Mathématiques')\n",
    "plt.xlabel('Catégorie de Score en Mathématiques')\n",
    "plt.ylabel('Effectif')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"indicator-variables\"></a>\n",
    "## 8. Encodage One-Hot (Variables Indicatrices/Variables Dummy)\n",
    "\n",
    "L'encodage one-hot crée des colonnes binaires (0 ou 1) pour chaque catégorie dans les variables catégorielles. Ces variables sont également connues sous le nom de variables indicatrices ou variables dummy. Cette technique est essentielle pour inclure des données catégorielles dans des modèles statistiques qui nécessitent des entrées numériques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer des variables dummy pour le genre en utilisant l'encodage one-hot\n",
    "gender_dummies = pd.get_dummies(df['gender'], prefix='gender')\n",
    "gender_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer des variables dummy pour la race/ethnicité en utilisant l'encodage one-hot\n",
    "race_dummies = pd.get_dummies(df['race/ethnicity'], prefix='race')\n",
    "race_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer des variables dummy pour le cours de préparation aux tests en utilisant l'encodage one-hot\n",
    "test_prep_dummies = pd.get_dummies(df['test_prep_course'], prefix='test_prep')\n",
    "test_prep_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner les variables dummy avec le dataframe original\n",
    "df_with_dummies = pd.concat([df, gender_dummies, race_dummies, test_prep_dummies], axis=1)\n",
    "\n",
    "# Afficher les premières lignes du dataframe avec les variables dummy\n",
    "df_with_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons supprimer les colonnes catégorielles d'origine si nous voulons ne conserver que les variables dummy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une copie du dataframe pour cet exemple\n",
    "df_encoded = df_with_dummies.copy()\n",
    "\n",
    "# Supprimer les colonnes d'origine (conserver une version pour référence)\n",
    "columns_to_drop = ['gender', 'race/ethnicity', 'test_prep_course']\n",
    "df_encoded = df_encoded.drop(columns=columns_to_drop)\n",
    "\n",
    "# Afficher les premières lignes du dataframe encodé\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"export-data\"></a>\n",
    "## 9. Exportation des Données Nettoyées\n",
    "\n",
    "Maintenant que nous avons nettoyé et transformé nos données, nous pouvons les exporter pour une analyse ultérieure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporter le dataframe original avec les fonctionnalités ajoutées\n",
    "df.to_csv('cleaned_students_performance_fr.csv', index=False)\n",
    "\n",
    "# Exporter le dataframe avec les variables dummy\n",
    "df_with_dummies.to_csv('students_performance_with_dummies_fr.csv', index=False)\n",
    "\n",
    "# Exporter le dataframe entièrement encodé\n",
    "df_encoded.to_csv('students_performance_encoded_fr.csv', index=False)\n",
    "\n",
    "print(\"Données exportées avec succès !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résumé\n",
    "\n",
    "Dans ce notebook, nous avons :\n",
    "\n",
    "1. Importé et exploré le jeu de données de performance des étudiants\n",
    "2. Vérifié et traité les valeurs manquantes\n",
    "3. Corrigé les formats de données\n",
    "4. Standardisé les données en créant de nouvelles fonctionnalités\n",
    "5. Normalisé les données numériques en utilisant la mise à l'échelle min-max et la standardisation z-score\n",
    "6. Créé des groupes pour les variables continues\n",
    "7. Généré des variables indicatrices pour les données catégorielles en utilisant l'encodage one-hot\n",
    "8. Exporté les données nettoyées et transformées pour une analyse ultérieure\n",
    "\n",
    "Ces techniques de préparation de données sont essentielles pour préparer les données brutes à l'analyse et à la modélisation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
